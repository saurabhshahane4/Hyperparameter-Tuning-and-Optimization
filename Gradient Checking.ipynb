{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Gradient Checking.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNejtzKgC3E6WEQMOrbhdaz"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"9q55ypGjG3MV","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596450988759,"user_tz":-330,"elapsed":1443,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wA0EU0b2KMJH","colab_type":"text"},"source":["1 dimensional gradient checking"]},{"cell_type":"code","metadata":{"id":"TvQgbY5eHYE8","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596450992018,"user_tz":-330,"elapsed":1341,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def forward_propagation(x, theta):\n","  '''Implement the linear forward propagation (compute J) presented in Figure 1 (J(theta) = theta * x)'''\n","  J = np.dot(theta,x)\n","\n","  return J\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"oQfYurTdHwuT","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596450997012,"user_tz":-330,"elapsed":1507,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def backward_propagation(x , theta):\n","  dtheta = x\n","\n","  return dtheta"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"o9itrrW8ILqt","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596451002290,"user_tz":-330,"elapsed":1688,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def gradient_check(x, theta, epsilon = 1e-7):\n","  thetaplus = theta + epsilon\n","  thetaminus = theta - epsilon\n","  J_plus = forward_propagation(x, thetaplus)\n","  J_minus = forward_propagation(x, thetaminus)\n","  gradapprox = (J_plus - J_minus)/(2 * epsilon)\n","\n","  grad = backward_propagation(x, theta)\n","\n","  numerator = np.linalg.norm(grad - gradapprox)\n","  denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)\n","\n","  difference = numerator / denominator\n","\n","  if difference < 1e-7:\n","    print(\"the gradient is correct\")\n","  else:\n","    print(\"the gradient is wrong\")\n","    "],"execution_count":4,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FdzSxBefKUvE","colab_type":"text"},"source":["**N Dimensional Gradient Checking**\n"]},{"cell_type":"code","metadata":{"id":"BqT9Z786Kcud","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596451006636,"user_tz":-330,"elapsed":1438,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def forward_propagation_n(X, Y, parameters):\n","\n","  m = X.shape[1]\n","  W1 = parameters['W1']\n","  b1 = parameters['b1']\n","  W2 = parameters['W2']\n","  b2 = parameters['b2']\n","  W3 = parameters['W3']\n","  b3 = parameters['b3']\n","\n","  # LINEAR -> RELU -> LINEAR -> RELU -> LINEAR -> SIGMOID\n","\n","  Z1 = np.dot(W1, X) + b1\n","  A1 = relu(Z1)\n","  Z2 = np.dot(W2, A1) + b2\n","  A2 = relu(Z2)\n","  Z3 = np.dot(W3, A2) + b3\n","  A3 = sigmoid(Z3)\n","\n","  #cost\n","  logprobs = np.multiply(-np.log(A3), Y)  + np.multiply(-np.log(1 - A3), 1 - Y)\n","  cost = 1./m * np.sum(longprobs)\n","\n","  cache = (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3)\n","\n","  return cost, cache\n","\n"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"4s72c9QNMsz0","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596451015826,"user_tz":-330,"elapsed":1176,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def backward_propagation_n(X, Y, cache):\n","  m = X.shape[1]\n","  (Z1, A1, W1, b1, Z2, A2, W2, b2, Z3, A3, W3, b3) = cache\n","\n","  dZ3 = A3 - Y\n","  dW3 = 1./ m*np.dot(dZ3, A2.T)\n","  db3 = 1./ m*np.dot(dZ3, axis = 1, keepdims = True)\n","\n","  dA2 = np.dot(W3.T, dZ3)\n","  dZ2 = np.multiply(dA2, np.int64(A2 > 0))\n","  dW2 = 1. / m * np.dot(dZ2, A1.T) * 2  # Should not multiply by 2\n","  db2 = 1. / m * np.sum(dZ2, axis=1, keepdims=True)\n","    \n","  dA1 = np.dot(W2.T, dZ2)\n","  dZ1 = np.multiply(dA1, np.int64(A1 > 0))\n","  dW1 = 1. / m * np.dot(dZ1, X.T)\n","  db1 = 4. / m * np.sum(dZ1, axis=1, keepdims=True) # Should not multiply by 4\n","    \n","  gradients = {\"dZ3\": dZ3, \"dW3\": dW3, \"db3\": db3,\n","                 \"dA2\": dA2, \"dZ2\": dZ2, \"dW2\": dW2, \"db2\": db2,\n","                 \"dA1\": dA1, \"dZ1\": dZ1, \"dW1\": dW1, \"db1\": db1}\n","    \n","  return gradients"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"oP6XWR0NNzXE","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1596451019075,"user_tz":-330,"elapsed":1224,"user":{"displayName":"Saurabh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjBC_TqONQ_b1COxua5zOunXaAKYuQBoL8SNELZjQ=s64","userId":"05893218404871049262"}}},"source":["def gradient_check_n(parameters, gradients, X, Y, epsilon = 1e-7):\n","  parameters_values, _ =dictionary_to_vector(parameters)\n","  grad = gradients_to_vector(gradients)\n","  num_parameters = parameters_values.shape[0]\n","  J_plus = np.zeros((num_parameters,1))\n","  J_minus = np.zeros((num_parameters,1))\n","  gradeapprox = np.zeros((num_parameters,1))\n","\n","  for i in range(num_parameters):\n","    thetaplus = np.copy(parameters_values)\n","    thetaplus[i][0] = thetaplus[i][0] + epsilon\n","    J_plus[i],_ = forward_propagation_n(X, Y, vector_dictionary(thetaplus))\n","\n","    thetaminus = np.copy(parameters_values)                                       \n","    thetaminus[i][0] = thetaminus[i][0] - epsilon                                       \n","    J_minus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaminus))\n","\n","\n","    gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n","\n","  numerator = np.linalg.norm(grad - gradapprox)                                     \n","  denominator = np.linalg.norm(grad) + np.linalg.norm(gradapprox)                   \n","  difference = numerator / denominator\n","\n","  if difference > 1e-7:\n","    print(\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n","  else:\n","    print(\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n","    \n","  return difference"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"mk2bsvxXQMvX","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}